# 漫画読解VLLMプロジェクト：人間と同等の理解を目指して

## プロジェクトの目的
本プロジェクトは、大規模言語モデル（LLM）および視覚言語モデル（VLM）が、日本語の漫画を人間のように完璧に読解できる環境を構築することを目的としています。

### 現状の課題
最新のハイエンドモデル（例：GPT-4o/GPT-5クラス、Claude 3.5/4クラス）であっても、日本語特有の縦書き、複雑なコマ割り、ルビ、擬音語、そして絵とテキストが密接に組み合わさった「漫画」という媒体を完璧に理解することは依然として困難です。

- **誤読**: 文字の認識エラーや読み順の混同。
- **文脈の欠如**: 視覚的なニュアンスやキャラクターの表情とセリフの不一致。
- **情報の断片化**: コマごとの情報の統合が不十分。

### 日本語漫画における読解の難所
漫画は単なる画像とテキストの集合体ではなく、独自の文法を持つ高度な情報媒体です。具体的には以下の要素がAIの理解を妨げるハードルとなっています。

1. **言語と書式の複雑性**
   - **ルビ（ふりがな）の多層的意味**: 漢字の読みを示すだけでなく、当て字や特殊なニュアンス（例：漢字「強敵」にルビ「とも」）を付与する演出。
   - **複雑な読解方向**: 基本は右から左（縦書き）だが、横書きの混在、さらに見開き2ページをまたぐ巨大なコマや視線誘導の存在。
2. **表現と演出の特異性**
   - **擬音・擬態語（描き文字）**: キャラクターや背景と重なるように描かれ、時にはコマをはみ出す演出。
   - **吹き出しの多様性**: 通常のセリフ、心の声、ナレーション、小声（小文字）、同時に発せられる複数人のセリフなどが多層的に配置。
3. **視覚的なメタ構造**
   - **時間軸の操作**: 背景の変化や吹き出しの形状による回想シーンの表現。
   - **レイヤー構造**: キャラクターがコマ枠を突き抜けたり、コマ同士が重なり合う動的な空間演出。

本プロジェクトは、これらの課題を「構造的なデータ化」と「マルチモーダルな学習」によって克服することを目指しています。

本プロジェクトは、これらの課題を補完し、AIによる「完璧な漫画読解」という領域に挑戦します。

## 実施内容
現在、以下のプロセスを通じて、モデルの読解能力を向上させるための基盤構築を行っています。

1. **高品質なアノテーションデータの構築**
   - コマの位置、読み順、テキストタイプ（セリフ/モノローグ/擬音）、キャラクターの特定など、詳細なメタデータを付与した独自のデータセットを作成。
2. **情報の抽出と補完のパイプライン化**
   - VLMが一度に全てを理解するのではなく、情報を構造的に整理して渡す仕組みを検討。

## 将来的・技術的なロードマップ
今後は、以下のモデルの採用やチューニングを検討し、特化型VLMの開発を加速させます。

### 1. Qwen-3 4B VL (Fine-tuning)
- 軽量ながら強力なVision能力を持つQwenシリーズをベースに、漫画特有の構造を学習させるためのファインチューニングを実施。
- エッジ環境や小規模なリソースでも動作する高性能な読解エンジンの構築。

### 2. Florence-2
- **セグメンテーション・キャプション生成**: ページ内の要素（キャラクター、吹き出し、コマ）を瞬時に分類・整理。
- **情報の集約**: Florence-2で抽出した構造的な情報をLLMに渡す、もしくは欠損情報を補完するためのフロントエンド・プロセッサとして活用。

### 3. その他次世代VLモデルの検証
- 日進月歩で進化する最新のVLモデルを取り込み、漫画のコンテキスト理解に最適なアーキテクチャを模索。

---
*「漫画をデータとして解析するのではなく、物語として理解するAIへ」*
